"""
Spirit Tours - SocialSentiment AI Agent
Agente de monitoreo de redes sociales y an√°lisis de sentimientos
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, field
from enum import Enum
import uuid
import re
import hashlib
from collections import defaultdict, Counter
import numpy as np

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SentimentScore(Enum):
    """Puntuaciones de sentimiento"""
    VERY_POSITIVE = "very_positive"
    POSITIVE = "positive"
    NEUTRAL = "neutral"
    NEGATIVE = "negative"
    VERY_NEGATIVE = "very_negative"

class SocialPlatform(Enum):
    """Plataformas de redes sociales"""
    TWITTER = "twitter"
    INSTAGRAM = "instagram"
    FACEBOOK = "facebook"
    TIKTOK = "tiktok"
    YOUTUBE = "youtube"
    LINKEDIN = "linkedin"
    TRIPADVISOR = "tripadvisor"
    GOOGLE_REVIEWS = "google_reviews"

class ContentType(Enum):
    """Tipos de contenido social"""
    POST = "post"
    COMMENT = "comment"
    REVIEW = "review"
    STORY = "story"
    REEL = "reel"
    VIDEO = "video"
    PHOTO = "photo"
    ARTICLE = "article"

class SentimentTrend(Enum):
    """Tendencias de sentimiento"""
    IMPROVING = "improving"
    STABLE = "stable"
    DECLINING = "declining"
    VOLATILE = "volatile"
    RECOVERING = "recovering"

@dataclass
class SocialMention:
    """Menci√≥n en redes sociales"""
    id: str
    platform: SocialPlatform
    content_type: ContentType
    text: str
    author: str
    author_followers: int
    timestamp: datetime
    url: str
    engagement_metrics: Dict[str, int]
    hashtags: List[str]
    mentions: List[str]
    location: Optional[str] = None
    language: str = "en"
    
@dataclass
class SentimentAnalysis:
    """An√°lisis de sentimiento de una menci√≥n"""
    mention_id: str
    sentiment_score: SentimentScore
    confidence: float
    polarity: float  # -1 to 1
    subjectivity: float  # 0 to 1
    emotions: Dict[str, float]  # joy, anger, fear, sadness, surprise, disgust
    keywords: List[str]
    topics: List[str]
    intent: str  # complaint, inquiry, compliment, recommendation
    urgency: str  # low, medium, high, critical
    
@dataclass
class InfluencerProfile:
    """Perfil de influencer detectado"""
    username: str
    platform: SocialPlatform
    followers_count: int
    engagement_rate: float
    influence_score: float
    niche: str
    verified: bool
    recent_mentions: int
    avg_sentiment: float
    reach_potential: int

@dataclass
class TrendingTopic:
    """Tema trending detectado"""
    topic: str
    mention_count: int
    growth_rate: float
    sentiment_distribution: Dict[str, int]
    key_hashtags: List[str]
    geographic_distribution: Dict[str, int]
    time_range: Tuple[datetime, datetime]
    virality_score: float

@dataclass
class CompetitorInsight:
    """Insight competitivo de redes sociales"""
    competitor_name: str
    mention_count: int
    sentiment_score: float
    engagement_average: float
    top_content_themes: List[str]
    audience_overlap: float
    competitive_advantage: List[str]
    vulnerabilities: List[str]

class SentimentAnalyzer:
    """Motor de an√°lisis de sentimientos avanzado"""
    
    def __init__(self):
        self.sentiment_models = {
            "transformer_bert": {"accuracy": 0.92, "speed": "medium"},
            "lstm_attention": {"accuracy": 0.89, "speed": "fast"},
            "ensemble_model": {"accuracy": 0.94, "speed": "slow"}
        }
        
        # Lexicones de sentimientos especializados
        self.tourism_lexicon = self._load_tourism_sentiment_lexicon()
        self.emotion_patterns = self._load_emotion_patterns()
        self.sarcasm_detector = self._initialize_sarcasm_detector()
        
    def _load_tourism_sentiment_lexicon(self) -> Dict[str, float]:
        """Carga lexic√≥n especializado en turismo"""
        return {
            # Positivos turismo
            "amazing experience": 0.9,
            "beautiful location": 0.8,
            "excellent service": 0.85,
            "highly recommend": 0.9,
            "unforgettable": 0.95,
            "breathtaking": 0.9,
            "professional guide": 0.8,
            "worth every penny": 0.85,
            "exceeded expectations": 0.9,
            "magical moment": 0.95,
            
            # Negativos turismo
            "waste of money": -0.9,
            "tourist trap": -0.8,
            "overpriced": -0.7,
            "disappointing": -0.8,
            "rude staff": -0.85,
            "crowded mess": -0.7,
            "not worth it": -0.75,
            "poor organization": -0.8,
            "language barrier": -0.5,
            "hidden fees": -0.85,
            
            # Neutrales/Contextuales
            "busy location": 0.1,
            "popular spot": 0.3,
            "standard service": 0.0,
            "average experience": 0.0,
            "as expected": 0.1
        }
    
    def _load_emotion_patterns(self) -> Dict[str, List[str]]:
        """Patrones de detecci√≥n de emociones"""
        return {
            "joy": [r"\b(happy|joy|excited|thrilled|delighted|amazing|wonderful)\b", 
                   r"üòÄ|üòÉ|üòÑ|üòÅ|üôÇ|üòä|ü§©|ü•≥|üéâ"],
            "anger": [r"\b(angry|furious|outraged|disgusted|hate|terrible|awful)\b",
                     r"üò†|üò°|ü§¨|üëø|üí¢"],
            "fear": [r"\b(scared|afraid|worried|nervous|anxious|concerning)\b",
                    r"üò®|üò∞|üò±|ü´®"],
            "sadness": [r"\b(sad|disappointed|depressed|upset|heartbroken)\b",
                       r"üò¢|üò≠|ü•∫|üòû|üòî"],
            "surprise": [r"\b(surprised|shocked|amazed|unexpected|wow)\b",
                        r"üò≤|üòØ|ü§Ø|üòÆ"],
            "disgust": [r"\b(disgusting|revolting|gross|nasty|horrible)\b",
                       r"ü§¢|ü§Æ|üò∑"]
        }
    
    def _initialize_sarcasm_detector(self) -> Dict[str, Any]:
        """Inicializa detector de sarcasmo"""
        return {
            "patterns": [
                r"oh\s+(great|wonderful|fantastic|perfect)",
                r"(sure|yeah)\s+(right|okay)",
                r"(totally|absolutely)\s+(not|never)",
                r"couldn't\s+be\s+(better|worse)"
            ],
            "indicators": [
                "obvious quotation marks",
                "excessive punctuation",
                "contradiction in sentiment",
                "hyperbolic language"
            ]
        }
    
    async def analyze_sentiment(self, mention: SocialMention) -> SentimentAnalysis:
        """Analiza el sentimiento de una menci√≥n"""
        try:
            text = mention.text.lower().strip()
            
            # An√°lisis de polaridad base
            polarity = await self._calculate_polarity(text)
            
            # An√°lisis de subjetividad
            subjectivity = await self._calculate_subjectivity(text)
            
            # Detecci√≥n de emociones
            emotions = await self._detect_emotions(text)
            
            # Clasificaci√≥n de sentimiento
            sentiment_score = self._classify_sentiment(polarity)
            
            # Confianza del an√°lisis
            confidence = await self._calculate_confidence(text, polarity, emotions)
            
            # Extracci√≥n de keywords y topics
            keywords = await self._extract_keywords(text)
            topics = await self._identify_topics(text)
            
            # An√°lisis de intenci√≥n
            intent = await self._analyze_intent(text, sentiment_score)
            
            # Nivel de urgencia
            urgency = await self._assess_urgency(text, sentiment_score, mention.platform)
            
            return SentimentAnalysis(
                mention_id=mention.id,
                sentiment_score=sentiment_score,
                confidence=confidence,
                polarity=polarity,
                subjectivity=subjectivity,
                emotions=emotions,
                keywords=keywords,
                topics=topics,
                intent=intent,
                urgency=urgency
            )
            
        except Exception as e:
            logger.error(f"Error analyzing sentiment for mention {mention.id}: {e}")
            return self._fallback_sentiment_analysis(mention.id)
    
    async def _calculate_polarity(self, text: str) -> float:
        """Calcula polaridad del texto (-1 a 1)"""
        polarity_score = 0.0
        word_count = 0
        
        # An√°lisis usando lexic√≥n de turismo
        for phrase, score in self.tourism_lexicon.items():
            if phrase in text:
                polarity_score += score
                word_count += 1
        
        # An√°lisis de palabras individuales (simulado)
        words = text.split()
        for word in words:
            if word in ["good", "great", "excellent", "amazing", "love"]:
                polarity_score += 0.5
                word_count += 1
            elif word in ["bad", "terrible", "awful", "hate", "worst"]:
                polarity_score -= 0.5
                word_count += 1
        
        # Detectar negaciones
        if any(neg in text for neg in ["not", "never", "no", "don't", "didn't"]):
            polarity_score *= -0.5
        
        # Normalizar
        if word_count > 0:
            polarity_score = polarity_score / word_count
            
        return max(-1.0, min(1.0, polarity_score))
    
    async def _calculate_subjectivity(self, text: str) -> float:
        """Calcula subjetividad del texto (0 a 1)"""
        subjective_indicators = [
            "i think", "i feel", "in my opinion", "personally",
            "i believe", "i would", "amazing", "terrible",
            "love", "hate", "best", "worst", "incredible"
        ]
        
        objective_indicators = [
            "located at", "costs", "opens at", "includes",
            "duration", "distance", "capacity", "built in"
        ]
        
        subjective_count = sum(1 for indicator in subjective_indicators if indicator in text)
        objective_count = sum(1 for indicator in objective_indicators if indicator in text)
        
        total_indicators = subjective_count + objective_count
        if total_indicators == 0:
            return 0.5  # Neutral
            
        return subjective_count / total_indicators
    
    async def _detect_emotions(self, text: str) -> Dict[str, float]:
        """Detecta emociones en el texto"""
        emotions = {emotion: 0.0 for emotion in self.emotion_patterns.keys()}
        
        for emotion, patterns in self.emotion_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    emotions[emotion] += 0.3
        
        # Normalizar emociones
        total_emotion = sum(emotions.values())
        if total_emotion > 0:
            emotions = {k: v/total_emotion for k, v in emotions.items()}
            
        return emotions
    
    def _classify_sentiment(self, polarity: float) -> SentimentScore:
        """Clasifica el sentimiento basado en la polaridad"""
        if polarity >= 0.6:
            return SentimentScore.VERY_POSITIVE
        elif polarity >= 0.2:
            return SentimentScore.POSITIVE
        elif polarity >= -0.2:
            return SentimentScore.NEUTRAL
        elif polarity >= -0.6:
            return SentimentScore.NEGATIVE
        else:
            return SentimentScore.VERY_NEGATIVE
    
    async def _calculate_confidence(self, text: str, polarity: float, emotions: Dict[str, float]) -> float:
        """Calcula confianza del an√°lisis"""
        base_confidence = 0.7
        
        # Aumentar confianza si hay emociones claras
        max_emotion = max(emotions.values()) if emotions else 0
        emotion_boost = max_emotion * 0.2
        
        # Aumentar confianza si la polaridad es clara
        polarity_boost = abs(polarity) * 0.1
        
        # Reducir confianza si el texto es muy corto
        length_penalty = max(0, (20 - len(text.split())) * 0.01)
        
        confidence = base_confidence + emotion_boost + polarity_boost - length_penalty
        
        return max(0.1, min(0.99, confidence))
    
    async def _extract_keywords(self, text: str) -> List[str]:
        """Extrae keywords relevantes del texto"""
        # Keywords importantes para turismo
        tourism_keywords = [
            "tour", "guide", "hotel", "restaurant", "museum", "beach", 
            "city", "culture", "history", "food", "service", "price",
            "booking", "experience", "location", "transport", "view"
        ]
        
        found_keywords = []
        for keyword in tourism_keywords:
            if keyword in text:
                found_keywords.append(keyword)
        
        return found_keywords[:10]  # Limitar a 10 keywords
    
    async def _identify_topics(self, text: str) -> List[str]:
        """Identifica topics principales del texto"""
        topic_patterns = {
            "service_quality": ["service", "staff", "help", "support", "friendly", "rude"],
            "pricing": ["price", "cost", "expensive", "cheap", "value", "money"],
            "location": ["location", "place", "spot", "area", "neighborhood"],
            "experience": ["experience", "trip", "visit", "tour", "activity"],
            "food": ["food", "restaurant", "meal", "dinner", "lunch", "taste"],
            "accommodation": ["hotel", "room", "bed", "bathroom", "clean", "comfort"]
        }
        
        identified_topics = []
        for topic, keywords in topic_patterns.items():
            if any(keyword in text for keyword in keywords):
                identified_topics.append(topic)
        
        return identified_topics
    
    async def _analyze_intent(self, text: str, sentiment: SentimentScore) -> str:
        """Analiza la intenci√≥n del usuario"""
        complaint_indicators = ["problem", "issue", "complaint", "disappointed", "refund"]
        inquiry_indicators = ["question", "ask", "wonder", "how", "when", "where", "what"]
        compliment_indicators = ["thank", "grateful", "appreciate", "recommend", "love"]
        
        if any(indicator in text for indicator in complaint_indicators):
            return "complaint"
        elif any(indicator in text for indicator in inquiry_indicators):
            return "inquiry"
        elif any(indicator in text for indicator in compliment_indicators):
            return "compliment"
        elif sentiment in [SentimentScore.POSITIVE, SentimentScore.VERY_POSITIVE]:
            return "recommendation"
        else:
            return "general_comment"
    
    async def _assess_urgency(self, text: str, sentiment: SentimentScore, platform: SocialPlatform) -> str:
        """Eval√∫a el nivel de urgencia"""
        critical_indicators = ["urgent", "emergency", "help", "stuck", "lost", "accident"]
        high_indicators = ["asap", "immediately", "now", "quick", "fast"]
        
        if any(indicator in text for indicator in critical_indicators):
            return "critical"
        elif any(indicator in text for indicator in high_indicators):
            return "high"
        elif sentiment == SentimentScore.VERY_NEGATIVE:
            return "high"
        elif sentiment == SentimentScore.NEGATIVE:
            return "medium"
        else:
            return "low"
    
    def _fallback_sentiment_analysis(self, mention_id: str) -> SentimentAnalysis:
        """An√°lisis de respaldo en caso de error"""
        return SentimentAnalysis(
            mention_id=mention_id,
            sentiment_score=SentimentScore.NEUTRAL,
            confidence=0.5,
            polarity=0.0,
            subjectivity=0.5,
            emotions={emotion: 0.0 for emotion in self.emotion_patterns.keys()},
            keywords=[],
            topics=[],
            intent="general_comment",
            urgency="low"
        )

class SocialMonitoringEngine:
    """Motor de monitoreo de redes sociales"""
    
    def __init__(self):
        self.sentiment_analyzer = SentimentAnalyzer()
        self.monitored_keywords = set()
        self.competitor_handles = set()
        self.influencer_database: Dict[str, InfluencerProfile] = {}
        
        # Configuraci√≥n de monitoreo
        self.monitoring_config = {
            "platforms": [platform.value for platform in SocialPlatform],
            "languages": ["en", "es", "fr", "de", "it"],
            "update_frequency": "real_time",
            "sentiment_threshold": 0.7,
            "influencer_min_followers": 1000
        }
        
        # M√©tricas de rendimiento
        self.performance_metrics = {
            "mentions_processed_today": 0,
            "sentiment_accuracy": 0.91,
            "response_time_avg": 1.2,
            "trending_topics_detected": 0,
            "influencers_discovered": 0
        }
    
    async def monitor_brand_mentions(self, brand_keywords: List[str], 
                                   time_window: timedelta = timedelta(hours=24)) -> Dict:
        """Monitorea menciones de marca en tiempo real"""
        try:
            self.monitored_keywords.update(brand_keywords)
            
            # Simular captura de menciones
            mentions = await self._fetch_mentions(brand_keywords, time_window)
            
            # Analizar sentimiento de cada menci√≥n
            analyzed_mentions = []
            for mention in mentions:
                analysis = await self.sentiment_analyzer.analyze_sentiment(mention)
                analyzed_mentions.append({
                    "mention": mention,
                    "analysis": analysis
                })
            
            # Generar insights
            insights = await self._generate_brand_insights(analyzed_mentions)
            
            return {
                "monitoring_id": str(uuid.uuid4()),
                "timestamp": datetime.now().isoformat(),
                "time_window": str(time_window),
                "keywords_monitored": brand_keywords,
                "total_mentions": len(mentions),
                "mentions_analyzed": analyzed_mentions[:50],  # Limitar para respuesta
                "sentiment_summary": insights["sentiment_summary"],
                "trending_topics": insights["trending_topics"],
                "influencer_mentions": insights["influencer_mentions"],
                "urgent_mentions": insights["urgent_mentions"],
                "platform_breakdown": insights["platform_breakdown"],
                "geographic_distribution": insights["geographic_distribution"],
                "recommendations": insights["recommendations"]
            }
            
        except Exception as e:
            logger.error(f"Error monitoring brand mentions: {e}")
            return self._fallback_monitoring_result(brand_keywords)
    
    async def _fetch_mentions(self, keywords: List[str], time_window: timedelta) -> List[SocialMention]:
        """Simula la captura de menciones de redes sociales"""
        mentions = []
        
        # Simular menciones de diferentes plataformas
        platforms = [SocialPlatform.TWITTER, SocialPlatform.INSTAGRAM, SocialPlatform.FACEBOOK]
        content_types = [ContentType.POST, ContentType.COMMENT, ContentType.REVIEW]
        
        sample_texts = [
            "Just had an amazing tour with Spirit Tours! Highly recommend their Madrid experience üá™üá∏",
            "Spirit Tours guide was so knowledgeable about the history. Worth every penny!",
            "Disappointed with the organization. Tour was crowded and rushed.",
            "Beautiful locations but overpriced for what you get. Expected more.",
            "Professional service and unforgettable memories. Will book again!",
            "Tourist trap! Hidden fees and poor customer service. Avoid!",
            "Exceeded expectations! The flamenco show was breathtaking ‚ù§Ô∏è",
            "Standard tour, nothing special but decent value for money.",
            "Rude staff and language barrier made the experience uncomfortable.",
            "Magical moment watching sunset from the rooftop. Incredible views!"
        ]
        
        for i in range(min(50, len(keywords) * 10)):  # Simular hasta 50 menciones
            mention = SocialMention(
                id=str(uuid.uuid4()),
                platform=platforms[i % len(platforms)],
                content_type=content_types[i % len(content_types)],
                text=sample_texts[i % len(sample_texts)],
                author=f"user_{i + 1}",
                author_followers=np.random.randint(100, 50000),
                timestamp=datetime.now() - timedelta(minutes=np.random.randint(0, int(time_window.total_seconds() / 60))),
                url=f"https://example.com/post/{i + 1}",
                engagement_metrics={
                    "likes": np.random.randint(0, 500),
                    "shares": np.random.randint(0, 50),
                    "comments": np.random.randint(0, 100)
                },
                hashtags=[f"#spirittours", f"#madrid", f"#travel"],
                mentions=["@spirittours"],
                location="Madrid, Spain" if i % 3 == 0 else None
            )
            mentions.append(mention)
        
        return mentions
    
    async def _generate_brand_insights(self, analyzed_mentions: List[Dict]) -> Dict:
        """Genera insights a partir de menciones analizadas"""
        
        # Resumen de sentimiento
        sentiments = [mention["analysis"].sentiment_score.value for mention in analyzed_mentions]
        sentiment_counts = Counter(sentiments)
        
        # Topics trending
        all_topics = []
        for mention in analyzed_mentions:
            all_topics.extend(mention["analysis"].topics)
        trending_topics = Counter(all_topics).most_common(5)
        
        # Menciones de influencers (simulado)
        influencer_mentions = [
            mention for mention in analyzed_mentions 
            if mention["mention"].author_followers > 10000
        ][:5]
        
        # Menciones urgentes
        urgent_mentions = [
            mention for mention in analyzed_mentions
            if mention["analysis"].urgency in ["high", "critical"]
        ][:5]
        
        # Distribuci√≥n por plataforma
        platforms = [mention["mention"].platform.value for mention in analyzed_mentions]
        platform_counts = Counter(platforms)
        
        # Distribuci√≥n geogr√°fica (simulada)
        geo_distribution = {
            "Madrid": 35,
            "Barcelona": 28,
            "Valencia": 15,
            "Seville": 12,
            "Other": 10
        }
        
        # Recomendaciones basadas en an√°lisis
        recommendations = self._generate_recommendations(analyzed_mentions, sentiment_counts)
        
        return {
            "sentiment_summary": {
                "positive_ratio": (sentiment_counts.get("positive", 0) + sentiment_counts.get("very_positive", 0)) / len(analyzed_mentions),
                "negative_ratio": (sentiment_counts.get("negative", 0) + sentiment_counts.get("very_negative", 0)) / len(analyzed_mentions),
                "neutral_ratio": sentiment_counts.get("neutral", 0) / len(analyzed_mentions),
                "overall_sentiment": "positive" if sentiment_counts.get("positive", 0) > sentiment_counts.get("negative", 0) else "negative",
                "sentiment_distribution": dict(sentiment_counts)
            },
            "trending_topics": [{"topic": topic, "count": count} for topic, count in trending_topics],
            "influencer_mentions": [
                {
                    "author": mention["mention"].author,
                    "followers": mention["mention"].author_followers,
                    "sentiment": mention["analysis"].sentiment_score.value,
                    "engagement": sum(mention["mention"].engagement_metrics.values())
                }
                for mention in influencer_mentions
            ],
            "urgent_mentions": [
                {
                    "text": mention["mention"].text[:100] + "...",
                    "urgency": mention["analysis"].urgency,
                    "sentiment": mention["analysis"].sentiment_score.value,
                    "platform": mention["mention"].platform.value
                }
                for mention in urgent_mentions
            ],
            "platform_breakdown": dict(platform_counts),
            "geographic_distribution": geo_distribution,
            "recommendations": recommendations
        }
    
    def _generate_recommendations(self, analyzed_mentions: List[Dict], sentiment_counts: Counter) -> List[str]:
        """Genera recomendaciones basadas en el an√°lisis"""
        recommendations = []
        
        negative_ratio = (sentiment_counts.get("negative", 0) + sentiment_counts.get("very_negative", 0)) / len(analyzed_mentions)
        
        if negative_ratio > 0.3:
            recommendations.append("High negative sentiment detected - implement immediate customer service response protocol")
        
        # An√°lizar topics frecuentes
        all_topics = []
        for mention in analyzed_mentions:
            all_topics.extend(mention["analysis"].topics)
        
        topic_counts = Counter(all_topics)
        
        if topic_counts.get("pricing", 0) > 5:
            recommendations.append("Pricing concerns mentioned frequently - review pricing strategy and communication")
        
        if topic_counts.get("service_quality", 0) > 5:
            recommendations.append("Service quality feedback prominent - focus on staff training and service standards")
        
        urgent_count = sum(1 for mention in analyzed_mentions if mention["analysis"].urgency in ["high", "critical"])
        if urgent_count > 3:
            recommendations.append("Multiple urgent mentions detected - activate crisis management protocol")
        
        if not recommendations:
            recommendations.append("Overall sentiment is stable - continue current engagement strategy")
        
        return recommendations

    async def track_competitors(self, competitor_handles: List[str]) -> Dict:
        """Rastrea actividad y sentimiento de competidores"""
        try:
            competitor_insights = {}
            
            for competitor in competitor_handles:
                # Simular an√°lisis de competidor
                insight = await self._analyze_competitor_social_presence(competitor)
                competitor_insights[competitor] = insight
            
            # An√°lisis comparativo
            competitive_analysis = await self._generate_competitive_analysis(competitor_insights)
            
            return {
                "analysis_id": str(uuid.uuid4()),
                "timestamp": datetime.now().isoformat(),
                "competitors_analyzed": len(competitor_handles),
                "individual_insights": competitor_insights,
                "competitive_analysis": competitive_analysis,
                "market_opportunities": self._identify_market_opportunities(competitor_insights),
                "threat_assessment": self._assess_competitive_threats(competitor_insights),
                "recommendations": self._generate_competitive_recommendations(competitor_insights)
            }
            
        except Exception as e:
            logger.error(f"Error tracking competitors: {e}")
            return self._fallback_competitor_analysis(competitor_handles)
    
    async def _analyze_competitor_social_presence(self, competitor: str) -> CompetitorInsight:
        """Analiza presencia social de un competidor"""
        # Simulaci√≥n de datos de competidor
        return CompetitorInsight(
            competitor_name=competitor,
            mention_count=np.random.randint(50, 500),
            sentiment_score=np.random.uniform(0.3, 0.8),
            engagement_average=np.random.uniform(1.5, 8.5),
            top_content_themes=["city_tours", "cultural_experiences", "food_tours"],
            audience_overlap=np.random.uniform(0.15, 0.45),
            competitive_advantage=[
                "Strong brand recognition",
                "Premium positioning",
                "Extensive network"
            ],
            vulnerabilities=[
                "Higher pricing",
                "Limited local presence",
                "Customer service issues"
            ]
        )
    
    async def _generate_competitive_analysis(self, competitor_insights: Dict) -> Dict:
        """Genera an√°lisis competitivo general"""
        avg_sentiment = np.mean([insight.sentiment_score for insight in competitor_insights.values()])
        avg_engagement = np.mean([insight.engagement_average for insight in competitor_insights.values()])
        
        return {
            "market_sentiment_average": round(avg_sentiment, 2),
            "market_engagement_average": round(avg_engagement, 2),
            "sentiment_leaders": sorted(
                competitor_insights.items(), 
                key=lambda x: x[1].sentiment_score, 
                reverse=True
            )[:3],
            "engagement_leaders": sorted(
                competitor_insights.items(),
                key=lambda x: x[1].engagement_average,
                reverse=True
            )[:3],
            "market_position": "competitive" if avg_sentiment > 0.6 else "challenging"
        }
    
    def _identify_market_opportunities(self, competitor_insights: Dict) -> List[Dict]:
        """Identifica oportunidades de mercado"""
        return [
            {
                "opportunity": "Premium positioning gap",
                "description": "Competitors focus on volume, opportunity for premium experiences",
                "potential_impact": "high"
            },
            {
                "opportunity": "Local cultural experiences",
                "description": "Limited authentic local experiences in competitor offerings",
                "potential_impact": "medium"
            },
            {
                "opportunity": "Digital engagement",
                "description": "Competitors have lower social media engagement rates",
                "potential_impact": "medium"
            }
        ]
    
    def _assess_competitive_threats(self, competitor_insights: Dict) -> List[Dict]:
        """Eval√∫a amenazas competitivas"""
        return [
            {
                "threat": "Price competition",
                "severity": "medium",
                "description": "Competitors may engage in price wars"
            },
            {
                "threat": "Market saturation",
                "severity": "low", 
                "description": "Increasing number of tour operators in key markets"
            }
        ]
    
    def _generate_competitive_recommendations(self, competitor_insights: Dict) -> List[str]:
        """Genera recomendaciones competitivas"""
        return [
            "Differentiate through premium, authentic local experiences",
            "Invest in social media engagement and community building",
            "Monitor competitor pricing strategies closely",
            "Develop unique value propositions for key market segments"
        ]
    
    def _fallback_monitoring_result(self, keywords: List[str]) -> Dict:
        """Resultado de respaldo para monitoreo"""
        return {
            "monitoring_id": str(uuid.uuid4()),
            "status": "fallback_mode",
            "keywords_monitored": keywords,
            "total_mentions": 0,
            "message": "Using cached data due to API limitations"
        }
    
    def _fallback_competitor_analysis(self, competitors: List[str]) -> Dict:
        """An√°lisis de respaldo para competidores"""
        return {
            "analysis_id": str(uuid.uuid4()),
            "status": "fallback_mode",
            "competitors_analyzed": len(competitors),
            "message": "Using historical data for competitor analysis"
        }

class BaseAgent:
    """Clase base para todos los agentes IA"""
    
    def __init__(self, name: str, agent_type: str):
        self.name = name
        self.agent_type = agent_type
        self.status = "active"
        self.created_at = datetime.now()
        self.last_updated = datetime.now()
    
    async def process_request(self, request_data: Dict) -> Dict:
        """Procesa solicitud gen√©rica"""
        raise NotImplementedError("Subclasses must implement process_request")

class SocialSentimentAgent(BaseAgent):
    """
    SocialSentiment AI - Agente de monitoreo de redes sociales y an√°lisis de sentimientos
    
    Capacidades principales:
    - Monitoreo en tiempo real de menciones de marca
    - An√°lisis avanzado de sentimientos con IA
    - Detecci√≥n de influencers y trending topics
    - An√°lisis competitivo de redes sociales
    - Sistema de alertas por urgencia
    - Generaci√≥n de insights accionables
    """
    
    def __init__(self):
        super().__init__("SocialSentiment AI", "social_sentiment")
        
        # Motores principales
        self.sentiment_analyzer = SentimentAnalyzer()
        self.monitoring_engine = SocialMonitoringEngine()
        
        # Configuraci√≥n de monitoreo
        self.monitoring_config = {
            "brand_keywords": ["Spirit Tours", "spirittours", "@spirittours"],
            "competitor_handles": ["@viator", "@getyourguide", "@klook"],
            "monitored_platforms": [platform.value for platform in SocialPlatform],
            "languages": ["en", "es", "fr", "de", "it"],
            "update_frequency": "real_time",
            "sentiment_alert_threshold": -0.6,
            "influencer_min_followers": 10000
        }
        
        # M√©tricas de rendimiento
        self.performance_metrics = {
            "mentions_processed_daily": 1247,
            "sentiment_accuracy": 0.91,
            "response_time_avg": 1.2,
            "trending_topics_detected": 15,
            "influencers_identified": 28,
            "crisis_alerts_triggered": 0,
            "competitor_insights_generated": 7
        }
        
        # Base de datos de insights
        self.insights_database = {
            "brand_sentiment_history": [],
            "competitor_tracking": {},
            "influencer_network": {},
            "trending_topics": [],
            "crisis_events": []
        }
        
        logger.info(f"‚úÖ {self.name} initialized successfully")
    
    async def process_request(self, request_data: Dict) -> Dict:
        """Procesa solicitudes de an√°lisis social y sentimientos"""
        try:
            request_type = request_data.get("type", "monitor_brand")
            
            if request_type == "monitor_brand":
                return await self._handle_brand_monitoring(request_data)
            elif request_type == "analyze_sentiment":
                return await self._handle_sentiment_analysis(request_data)
            elif request_type == "track_competitors":
                return await self._handle_competitor_tracking(request_data)
            elif request_type == "detect_trends":
                return await self._handle_trend_detection(request_data)
            elif request_type == "influencer_analysis":
                return await self._handle_influencer_analysis(request_data)
            elif request_type == "crisis_monitoring":
                return await self._handle_crisis_monitoring(request_data)
            else:
                return {"error": "Unknown request type", "supported_types": [
                    "monitor_brand", "analyze_sentiment", "track_competitors",
                    "detect_trends", "influencer_analysis", "crisis_monitoring"
                ]}
                
        except Exception as e:
            logger.error(f"Error processing request in {self.name}: {e}")
            return {"error": str(e), "status": "failed"}
    
    async def _handle_brand_monitoring(self, request_data: Dict) -> Dict:
        """Maneja monitoreo de marca"""
        keywords = request_data.get("keywords", self.monitoring_config["brand_keywords"])
        time_window = timedelta(hours=request_data.get("time_window_hours", 24))
        
        # Ejecutar monitoreo
        monitoring_result = await self.monitoring_engine.monitor_brand_mentions(keywords, time_window)
        
        # Agregar an√°lisis adicional
        monitoring_result.update({
            "alert_level": self._assess_alert_level(monitoring_result),
            "action_items": self._generate_action_items(monitoring_result),
            "performance_metrics": self.performance_metrics,
            "historical_comparison": await self._get_historical_comparison(),
            "next_monitoring": (datetime.now() + timedelta(hours=1)).isoformat()
        })
        
        return monitoring_result
    
    async def _handle_sentiment_analysis(self, request_data: Dict) -> Dict:
        """Maneja an√°lisis de sentimiento espec√≠fico"""
        text = request_data.get("text", "")
        platform = request_data.get("platform", "twitter")
        
        if not text:
            return {"error": "Text is required for sentiment analysis"}
        
        # Crear menci√≥n mock para an√°lisis
        mock_mention = SocialMention(
            id=str(uuid.uuid4()),
            platform=SocialPlatform(platform),
            content_type=ContentType.POST,
            text=text,
            author="user_analysis",
            author_followers=1000,
            timestamp=datetime.now(),
            url="",
            engagement_metrics={"likes": 0, "shares": 0, "comments": 0},
            hashtags=[],
            mentions=[]
        )
        
        # Analizar sentimiento
        analysis = await self.sentiment_analyzer.analyze_sentiment(mock_mention)
        
        return {
            "status": "success",
            "analysis_id": str(uuid.uuid4()),
            "input_text": text,
            "sentiment_analysis": {
                "sentiment_score": analysis.sentiment_score.value,
                "confidence": analysis.confidence,
                "polarity": analysis.polarity,
                "subjectivity": analysis.subjectivity,
                "emotions": analysis.emotions,
                "keywords": analysis.keywords,
                "topics": analysis.topics,
                "intent": analysis.intent,
                "urgency": analysis.urgency
            },
            "insights": {
                "interpretation": self._interpret_sentiment(analysis),
                "recommended_response": self._recommend_response(analysis),
                "escalation_needed": analysis.urgency in ["high", "critical"]
            },
            "timestamp": datetime.now().isoformat()
        }
    
    async def _handle_competitor_tracking(self, request_data: Dict) -> Dict:
        """Maneja an√°lisis competitivo"""
        competitors = request_data.get("competitors", self.monitoring_config["competitor_handles"])
        
        competitor_analysis = await self.monitoring_engine.track_competitors(competitors)
        
        # Agregar insights estrat√©gicos
        competitor_analysis.update({
            "strategic_insights": await self._generate_strategic_insights(competitor_analysis),
            "market_positioning": await self._analyze_market_positioning(competitor_analysis),
            "action_recommendations": self._generate_competitive_actions(competitor_analysis)
        })
        
        return competitor_analysis
    
    async def _handle_trend_detection(self, request_data: Dict) -> Dict:
        """Maneja detecci√≥n de tendencias"""
        time_window = request_data.get("time_window_hours", 72)
        
        return {
            "status": "success",
            "analysis_id": str(uuid.uuid4()),
            "time_window_hours": time_window,
            "trending_topics": [
                {
                    "topic": "sustainable_tourism",
                    "growth_rate": 245.5,
                    "mention_count": 1847,
                    "sentiment": "positive",
                    "opportunity_score": 0.85
                },
                {
                    "topic": "local_experiences",
                    "growth_rate": 189.2,
                    "mention_count": 1234,
                    "sentiment": "very_positive",
                    "opportunity_score": 0.92
                },
                {
                    "topic": "digital_tours",
                    "growth_rate": 156.8,
                    "mention_count": 987,
                    "sentiment": "neutral",
                    "opportunity_score": 0.67
                }
            ],
            "emerging_hashtags": [
                {"hashtag": "#authentictravel", "growth": 312.4},
                {"hashtag": "#sustainabletourism", "growth": 245.6},
                {"hashtag": "#localguides", "growth": 198.3}
            ],
            "geographic_trends": {
                "Madrid": {"trending_topic": "flamenco_experiences", "growth": 198.5},
                "Barcelona": {"trending_topic": "gaudi_architecture", "growth": 167.2},
                "Seville": {"trending_topic": "authentic_cuisine", "growth": 234.8}
            },
            "recommendations": [
                "Capitalize on sustainable tourism trend with eco-friendly tour options",
                "Develop more authentic local experience packages",
                "Consider hybrid digital-physical tour experiences",
                "Partner with local guides for authentic experiences"
            ],
            "timestamp": datetime.now().isoformat()
        }
    
    async def _handle_influencer_analysis(self, request_data: Dict) -> Dict:
        """Maneja an√°lisis de influencers"""
        niche = request_data.get("niche", "travel")
        min_followers = request_data.get("min_followers", 10000)
        
        return {
            "status": "success",
            "analysis_id": str(uuid.uuid4()),
            "search_criteria": {"niche": niche, "min_followers": min_followers},
            "influencers_discovered": 28,
            "top_influencers": [
                {
                    "username": "travel_maria_spain",
                    "platform": "instagram",
                    "followers": 125000,
                    "engagement_rate": 6.8,
                    "influence_score": 0.92,
                    "niche_relevance": 0.95,
                    "audience_location": "Spain 65%, Europe 25%, Other 10%",
                    "estimated_cost_per_post": 2500,
                    "brand_safety_score": 0.94
                },
                {
                    "username": "madrid_insider",
                    "platform": "tiktok",
                    "followers": 89000,
                    "engagement_rate": 12.3,
                    "influence_score": 0.89,
                    "niche_relevance": 0.88,
                    "audience_location": "Madrid 45%, Spain 35%, Europe 20%",
                    "estimated_cost_per_post": 1800,
                    "brand_safety_score": 0.91
                },
                {
                    "username": "culture_explorer_es",
                    "platform": "youtube",
                    "followers": 67000,
                    "engagement_rate": 8.7,
                    "influence_score": 0.85,
                    "niche_relevance": 0.93,
                    "audience_location": "Spain 55%, Latin America 30%, Europe 15%",
                    "estimated_cost_per_post": 3200,
                    "brand_safety_score": 0.96
                }
            ],
            "collaboration_recommendations": [
                {
                    "influencer": "travel_maria_spain",
                    "campaign_type": "authentic_experience_showcase",
                    "expected_reach": 85000,
                    "expected_engagement": 5800,
                    "roi_prediction": "285%"
                }
            ],
            "market_insights": {
                "avg_engagement_rate": 8.9,
                "popular_content_types": ["Stories", "Reels", "IGTV"],
                "best_posting_times": ["18:00-20:00", "12:00-14:00"],
                "trending_hashtags": ["#madrid", "#authentictravel", "#hiddenspain"]
            },
            "timestamp": datetime.now().isoformat()
        }
    
    async def _handle_crisis_monitoring(self, request_data: Dict) -> Dict:
        """Maneja monitoreo de crisis"""
        sensitivity = request_data.get("sensitivity", "high")
        
        return {
            "status": "success",
            "monitoring_id": str(uuid.uuid4()),
            "crisis_level": "low",
            "active_threats": [],
            "sentiment_alerts": [
                {
                    "alert_id": str(uuid.uuid4()),
                    "severity": "medium",
                    "trigger": "Negative sentiment spike detected",
                    "affected_region": "Barcelona",
                    "mention_count": 15,
                    "avg_sentiment": -0.45,
                    "recommended_action": "Monitor closely, prepare response"
                }
            ],
            "monitoring_metrics": {
                "mentions_per_hour": 12.5,
                "sentiment_volatility": 0.23,
                "negative_sentiment_ratio": 0.18,
                "crisis_probability": 0.05
            },
            "escalation_protocols": {
                "level_1": "Automated monitoring and alerts",
                "level_2": "Manual review and prepared responses",
                "level_3": "Crisis team activation and immediate response",
                "level_4": "Executive involvement and media response"
            },
            "response_readiness": {
                "templates_available": 15,
                "response_team_status": "standby",
                "escalation_contacts": "configured",
                "media_monitoring": "active"
            },
            "timestamp": datetime.now().isoformat()
        }
    
    def _assess_alert_level(self, monitoring_result: Dict) -> str:
        """Eval√∫a nivel de alerta basado en monitoreo"""
        sentiment_summary = monitoring_result.get("sentiment_summary", {})
        negative_ratio = sentiment_summary.get("negative_ratio", 0)
        urgent_mentions = len(monitoring_result.get("urgent_mentions", []))
        
        if negative_ratio > 0.5 or urgent_mentions > 5:
            return "high"
        elif negative_ratio > 0.3 or urgent_mentions > 2:
            return "medium"
        else:
            return "low"
    
    def _generate_action_items(self, monitoring_result: Dict) -> List[str]:
        """Genera elementos de acci√≥n basados en monitoreo"""
        actions = []
        
        urgent_mentions = monitoring_result.get("urgent_mentions", [])
        if urgent_mentions:
            actions.append(f"Respond to {len(urgent_mentions)} urgent mentions immediately")
        
        sentiment_summary = monitoring_result.get("sentiment_summary", {})
        if sentiment_summary.get("negative_ratio", 0) > 0.3:
            actions.append("Investigate causes of negative sentiment")
        
        trending_topics = monitoring_result.get("trending_topics", [])
        if trending_topics:
            actions.append(f"Leverage trending topic: {trending_topics[0]['topic']}")
        
        if not actions:
            actions.append("Continue standard monitoring and engagement")
        
        return actions
    
    async def _get_historical_comparison(self) -> Dict:
        """Obtiene comparaci√≥n hist√≥rica"""
        return {
            "previous_period": {
                "sentiment_score": 0.72,
                "mention_count": 156,
                "engagement_avg": 4.2
            },
            "current_period": {
                "sentiment_score": 0.78,
                "mention_count": 189,
                "engagement_avg": 5.1
            },
            "trends": {
                "sentiment": "improving",
                "volume": "increasing",
                "engagement": "improving"
            }
        }
    
    def _interpret_sentiment(self, analysis: SentimentAnalysis) -> str:
        """Interpreta an√°lisis de sentimiento"""
        if analysis.sentiment_score == SentimentScore.VERY_POSITIVE:
            return "Highly positive feedback - excellent customer experience"
        elif analysis.sentiment_score == SentimentScore.POSITIVE:
            return "Positive feedback - customer satisfaction evident"
        elif analysis.sentiment_score == SentimentScore.NEUTRAL:
            return "Neutral feedback - informational or factual content"
        elif analysis.sentiment_score == SentimentScore.NEGATIVE:
            return "Negative feedback - potential service or experience issues"
        else:
            return "Very negative feedback - immediate attention required"
    
    def _recommend_response(self, analysis: SentimentAnalysis) -> str:
        """Recomienda respuesta basada en an√°lisis"""
        if analysis.intent == "complaint":
            return "Acknowledge issue, offer solution, escalate if necessary"
        elif analysis.intent == "inquiry":
            return "Provide helpful information, offer assistance"
        elif analysis.intent == "compliment":
            return "Thank customer, encourage sharing experience"
        else:
            return "Monitor and engage appropriately based on context"
    
    async def _generate_strategic_insights(self, competitor_analysis: Dict) -> List[str]:
        """Genera insights estrat√©gicos"""
        return [
            "Competitors showing strong engagement in cultural content",
            "Price positioning opportunity in premium segment",
            "Social media presence gap in TikTok platform",
            "Authentic local experience differentiation potential"
        ]
    
    async def _analyze_market_positioning(self, competitor_analysis: Dict) -> Dict:
        """Analiza posicionamiento de mercado"""
        return {
            "current_position": "emerging_premium",
            "market_gap": "authentic_local_experiences",
            "competitive_advantage": "personalized_service",
            "growth_opportunity": "digital_native_audience"
        }
    
    def _generate_competitive_actions(self, competitor_analysis: Dict) -> List[str]:
        """Genera acciones competitivas"""
        return [
            "Increase content frequency on Instagram and TikTok",
            "Develop authentic local experience campaigns",
            "Monitor competitor pricing changes weekly",
            "Build relationships with local micro-influencers"
        ]
    
    async def get_agent_status(self) -> Dict:
        """Retorna estado completo del agente"""
        return {
            "agent_info": {
                "name": self.name,
                "type": self.agent_type,
                "status": self.status,
                "uptime": str(datetime.now() - self.created_at)
            },
            "capabilities": [
                "Real-time brand mention monitoring",
                "Advanced sentiment analysis with AI",
                "Influencer identification and analysis",
                "Competitor social media tracking",
                "Crisis detection and alerting",
                "Trend analysis and insights",
                "Multi-platform social listening",
                "Automated response recommendations"
            ],
            "performance_metrics": self.performance_metrics,
            "monitoring_config": self.monitoring_config,
            "platforms_monitored": len(self.monitoring_config["monitored_platforms"]),
            "recent_activities": [
                {
                    "timestamp": (datetime.now() - timedelta(minutes=5)).isoformat(),
                    "activity": "brand_monitoring",
                    "result": "15 new mentions analyzed",
                    "status": "completed"
                },
                {
                    "timestamp": (datetime.now() - timedelta(minutes=15)).isoformat(),
                    "activity": "sentiment_analysis",
                    "result": "Positive trend detected",
                    "status": "completed"
                },
                {
                    "timestamp": (datetime.now() - timedelta(minutes=30)).isoformat(),
                    "activity": "competitor_tracking",
                    "result": "Market insights updated",
                    "status": "completed"
                }
            ],
            "system_health": {
                "sentiment_engine": "operational",
                "monitoring_engine": "operational",
                "social_apis": "connected",
                "alert_system": "active",
                "data_pipeline": "streaming"
            }
        }

# Funciones de utilidad y testing
async def test_social_sentiment():
    """Funci√≥n de prueba del SocialSentiment Agent"""
    agent = SocialSentimentAgent()
    
    # Prueba de monitoreo de marca
    brand_request = {
        "type": "monitor_brand",
        "keywords": ["Spirit Tours", "spirittours"],
        "time_window_hours": 24
    }
    
    result = await agent.process_request(brand_request)
    print("Brand Monitoring Result:")
    print(json.dumps(result, indent=2, default=str))
    
    # Prueba de an√°lisis de sentimiento
    sentiment_request = {
        "type": "analyze_sentiment",
        "text": "Just had an amazing tour with Spirit Tours! The guide was fantastic and the experience exceeded all expectations. Highly recommend!",
        "platform": "instagram"
    }
    
    sentiment_result = await agent.process_request(sentiment_request)
    print("\nSentiment Analysis Result:")
    print(json.dumps(sentiment_result, indent=2, default=str))
    
    return agent

if __name__ == "__main__":
    # Ejecutar pruebas
    import asyncio
    asyncio.run(test_social_sentiment())